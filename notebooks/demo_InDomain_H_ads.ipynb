{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c0dd83",
   "metadata": {},
   "source": [
    "# Demo workflow: *EqV2* H-adsorption relaxations on (2 2 1) slabs\n",
    "\n",
    "This Jupyter notebook reproduces the key steps used in ACS journal submitted article.\n",
    "It demonstrates how to:\n",
    "1. set up the exact software environment (matching the paper),\n",
    "2. build (2 2 1) slabs from a small Bulk dataset,\n",
    "3. generate heuristic **+** random H adsorption sites,\n",
    "4. relax each configuration with the *EquiformerV2-31 M* surrogate model, and\n",
    "5. post-process trajectories to extract *min-energy* structures, force metrics, adsorption‚Äêsite type, and slab metadata.\n",
    "\n",
    "The notebook is self-contained: simply run sequentially inside any **GPU‚Äêenabled** Python 3.10+ environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32053fe",
   "metadata": {},
   "source": [
    "## 0. Software setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --extra-index-url https://download.pytorch.org/whl/cu121 \\\n",
    "            torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121\n",
    "!pip install --quiet pyg_lib torch_scatter==2.1.2+pt23cu121 torch_sparse==0.6.18+pt23cu121 \\\n",
    "            torch_cluster==1.6.3+pt23cu121 torch_spline_conv==1.2.2+pt23cu121 \\\n",
    "            -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "!pip install --quiet torch_geometric==2.6.1\n",
    "!pip install --quiet numpy==1.26.4 pandas==2.2.2 fairchem-core==1.2.0 fairchem-data-oc==0.0.1 \\\n",
    "            pymatgen==2024.10.3 ase==3.23.0 tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af41420",
   "metadata": {},
   "source": [
    "## 1. Imports & input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle, shutil, re\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, ase.io as aseio\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fairchem.core.common.relaxation.ase_utils import OCPCalculator\n",
    "from fairchem.core.models.model_registry import model_name_to_local_file\n",
    "from fairchem.data.oc.core import Bulk, Slab, Adsorbate, AdsorbateSlabConfig\n",
    "from fairchem.data.oc.utils import DetectTrajAnomaly\n",
    "from ase.optimize import BFGS\n",
    "import fairchem.data.oc\n",
    "\n",
    "# ---- load a small bulk dataset --------------------------------------------------\n",
    "work_pkl = Path('InDomainBulk.pkl')              # <-- provide with repo (tiny demo set)\n",
    "assert work_pkl.exists(), 'InDomainBulk.pkl not found!'  # keep users honest\n",
    "\n",
    "with open(work_pkl, 'rb') as f:\n",
    "    bulks = pickle.load(f)\n",
    "bulk_ids = [b['src_id'] for b in bulks][:2]      # demo ‚Üí first two IDs\n",
    "print('Demo bulk IDs:', bulk_ids)\n",
    "\n",
    "# adsorbate DB\n",
    "ads_db = Path(fairchem.data.oc.__file__).parent/'databases/pkls/adsorbates.pkl'\n",
    "ads_H  = Adsorbate(adsorbate_smiles_from_db='*H', adsorbate_db_path=ads_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f1f56",
   "metadata": {},
   "source": [
    "## 2. Surrogate calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da85de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = model_name_to_local_file('EquiformerV2-31M-S2EF-OC20-All+MD',\n",
    "                               local_cache='/tmp/ocp_checkpoints/')\n",
    "calc = OCPCalculator(checkpoint_path=ckpt, cpu=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1e3c7",
   "metadata": {},
   "source": [
    "## 3. Build (2 2 1) slabs & relax H configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a61a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIENT      = (2, 2, 1)\n",
    "orient_tag  = ''.join(map(str, ORIENT))          # '221'\n",
    "OUT_ROOT    = f'InDomain{orient_tag}'\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for bid in tqdm(bulk_ids, desc='Bulks'):\n",
    "    bulk  = Bulk(bulk_src_id_from_db=bid, bulk_db_path=str(work_pkl))\n",
    "    slabs = Slab.from_bulk_get_specific_millers(bulk=bulk, specific_millers=ORIENT)\n",
    "\n",
    "    for sidx, slab in enumerate(slabs):\n",
    "        heur = AdsorbateSlabConfig(slab, ads_H, mode='heuristic')\n",
    "        rand = AdsorbateSlabConfig(slab, ads_H, mode='random_site_heuristic_placement', num_sites=20)\n",
    "        configs = [*heur.atoms_list, *rand.atoms_list]\n",
    "\n",
    "        out_dir = f'{OUT_ROOT}/{bid}_H_{sidx}'\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        print(f'üü¢ {len(configs)} configs ‚Üí {out_dir}')\n",
    "\n",
    "        for cidx, atoms in enumerate(configs):\n",
    "            atoms.calc = calc\n",
    "            BFGS(atoms,\n",
    "                 trajectory=f'{out_dir}/config_{cidx}.traj',\n",
    "                 logfile   =f'{out_dir}/config_{cidx}.log').run(fmax=0.05, steps=100)\n",
    "\n",
    "print('Relaxations finished in', round(time.time()-start,1), 's')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b90b8",
   "metadata": {},
   "source": [
    "## 4. Post-process trajectories ‚Üí min-energy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec60886",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for slab_dir in Path(OUT_ROOT).glob('*_H_*'):\n",
    "    base    = slab_dir.name                  # e.g. mp-123_H_0\n",
    "    bulk_id, _, slab_idx = base.split('_')   # slab_idx str\n",
    "    key = f'{bulk_id}_H_{slab_idx}_{orient_tag}'\n",
    "\n",
    "    good = []\n",
    "    for traj_file in slab_dir.glob('*.traj'):\n",
    "        traj = aseio.read(traj_file, ':')\n",
    "        det  = DetectTrajAnomaly(traj[0], traj[-1], traj[0].get_tags())\n",
    "        if any([det.is_adsorbate_dissociated(), det.is_adsorbate_desorbed(),\n",
    "                det.has_surface_changed(), det.is_adsorbate_intercalated()]):\n",
    "            continue\n",
    "        E = traj[-1].get_potential_energy()\n",
    "        F = traj[-1].get_forces()\n",
    "        good.append({'E':E, 'F':F, 'file':str(traj_file)})\n",
    "\n",
    "    if good:\n",
    "        best  = min(good, key=lambda d: d['E'])\n",
    "        max_F = np.linalg.norm(best['F'], axis=1).max()\n",
    "        records.append(dict(key=key, bulk_id=bulk_id, slab_index=int(slab_idx),\n",
    "                           orientation=orient_tag, adsorbate='H',\n",
    "                           min_E_ml=best['E'], max_F_ml=max_F,\n",
    "                           traj_file=best['file']))\n",
    "\n",
    "df_min = pd.DataFrame(records)\n",
    "print('Rows collected :', len(df_min))\n",
    "df_min.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add65417",
   "metadata": {},
   "source": [
    "## 5. Adsorption-site classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from ase.io import read\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# helper 1 ‚Äì tile slab until the two in-plane cell vectors ‚â• min_ab √Ö\n",
    "# ------------------------------------------------------------------\n",
    "def tile_substrate(atoms, min_ab: float = 8.0):\n",
    "    tags = atoms.get_tags()\n",
    "    sub, ads = atoms[tags != 2], atoms[tags == 2]          # adsorbate has tag==2\n",
    "    a_len, b_len = np.linalg.norm(sub.cell[0]), np.linalg.norm(sub.cell[1])\n",
    "    na, nb = max(1, math.ceil(min_ab / a_len)), max(1, math.ceil(min_ab / b_len))\n",
    "    return sub.repeat((na, nb, 1)) + ads\n",
    "\n",
    "# simple map: neighbour-count ‚Üí site label\n",
    "classify = {1: \"top\", 2: \"bridge\", 3: \"3-fold\", 4: \"4-fold\"}.get\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# helper 2 ‚Äì indices of nearest surface atoms to adsorbate\n",
    "# ------------------------------------------------------------------\n",
    "def nearest_idx(atoms, ads_i: int, surf_idx, tol: float = 0.10):\n",
    "    \"\"\"Return indices of all surface atoms within (1+tol)*d_min of adsorbate.\"\"\"\n",
    "    dists = atoms.get_distances(ads_i, surf_idx, mic=True)\n",
    "    pairs = sorted([(d, j) for d, j in zip(dists, surf_idx) if d > 0],\n",
    "                   key=lambda x: x[0])\n",
    "\n",
    "    if not pairs:                       # <-- safety: empty list\n",
    "        return []\n",
    "\n",
    "    cutoff = pairs[0][0] * (1 + tol)    # first entry = d_min\n",
    "    return [j for d, j in pairs if d <= cutoff]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# main row-wise routine\n",
    "# ------------------------------------------------------------------\n",
    "def site_info(row):\n",
    "    \"\"\"Attach site type & nearest surface-atom symbols for one relaxed traj.\"\"\"\n",
    "    try:\n",
    "        atoms = read(row.traj_file, index=-1)              # last frame only\n",
    "        tiled = tile_substrate(atoms)                      # enlarge supercell\n",
    "        tags  = tiled.get_tags()\n",
    "        ads_i = int(np.where(tags == 2)[0][0])             # first adsorbate atom\n",
    "        surf  = np.where(tags == 1)[0]                     # surface atoms\n",
    "        near  = nearest_idx(tiled, ads_i, surf)\n",
    "\n",
    "        site_type = classify(len(near), \"unknown\")\n",
    "        near_syms = [tiled[i].symbol for i in near] if near else None\n",
    "\n",
    "        return pd.Series({\"site_type\": site_type,\n",
    "                          \"nearest_atoms\": near_syms})\n",
    "    except Exception as err:\n",
    "        # if anything goes wrong keep the DF intact & show None\n",
    "        return pd.Series({\"site_type\": None,\n",
    "                          \"nearest_atoms\": None})\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# apply to your minima DataFrame\n",
    "# ------------------------------------------------------------------\n",
    "df_min[[\"site_type\", \"nearest_atoms\"]] = df_min.apply(site_info, axis=1)\n",
    "df_min.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3897ad",
   "metadata": {},
   "source": [
    "## 6. Add slab shift / top metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def shift_top(slab):\n",
    "    m = re.search(r'\\([^)]*\\),\\s*([-+]?\\d*\\.?\\d+),\\s*(True|False)', str(slab))\n",
    "    return (np.nan,np.nan) if m is None else (float(m.group(1)), m.group(2)=='True')\n",
    "\n",
    "cache = {}\n",
    "for key in df_min.key.unique():\n",
    "    bid,_,idx,_ = key.split('_')\n",
    "    idx = int(idx)\n",
    "    if (bid,idx) in cache: continue\n",
    "    slabs = Slab.from_bulk_get_specific_millers(Bulk(bid, str(work_pkl)), ORIENT)\n",
    "    cache[(bid,idx)] = shift_top(slabs[idx]) if idx < len(slabs) else (np.nan,np.nan)\n",
    "\n",
    "df_min[['shift','top']] = df_min.apply(lambda r: pd.Series(cache[(r.bulk_id,r.slab_index)]), axis=1)\n",
    "df_min.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5be5f",
   "metadata": {},
   "source": [
    "## 7. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a62a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv = f'{OUT_ROOT}_minE_clean.csv'\n",
    "df_min.to_csv(out_csv, index=False)\n",
    "print('Saved ‚Üí', out_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351430aa",
   "metadata": {},
   "source": [
    "---\n",
    "**Notebook generated:** 2025-07-10 19:21 UTC\n",
    "\n",
    "*Correspondence*: i.c.oguz@differ.nl"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
